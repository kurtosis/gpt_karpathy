{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a04015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440674e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef458698",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edbcd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dataset {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d09545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e457adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4161c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbb535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map chars to integers\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ababd67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ec0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "272ce19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context tensor([18]) produces target 47\n",
      "context tensor([18, 47]) produces target 56\n",
      "context tensor([18, 47, 56]) produces target 57\n",
      "context tensor([18, 47, 56, 57]) produces target 58\n",
      "context tensor([18, 47, 56, 57, 58]) produces target 1\n",
      "context tensor([18, 47, 56, 57, 58,  1]) produces target 15\n",
      "context tensor([18, 47, 56, 57, 58,  1, 15]) produces target 47\n",
      "context tensor([18, 47, 56, 57, 58,  1, 15, 47]) produces target 58\n"
     ]
    }
   ],
   "source": [
    "# time dimension\n",
    "block_size=8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"context {context} produces target {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1126cba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "input [24] gives target 43\n",
      "input [24, 43] gives target 58\n",
      "input [24, 43, 58] gives target 5\n",
      "input [24, 43, 58, 5] gives target 57\n",
      "input [24, 43, 58, 5, 57] gives target 1\n",
      "input [24, 43, 58, 5, 57, 1] gives target 46\n",
      "input [24, 43, 58, 5, 57, 1, 46] gives target 43\n",
      "input [24, 43, 58, 5, 57, 1, 46, 43] gives target 39\n",
      "input [44] gives target 53\n",
      "input [44, 53] gives target 56\n",
      "input [44, 53, 56] gives target 1\n",
      "input [44, 53, 56, 1] gives target 58\n",
      "input [44, 53, 56, 1, 58] gives target 46\n",
      "input [44, 53, 56, 1, 58, 46] gives target 39\n",
      "input [44, 53, 56, 1, 58, 46, 39] gives target 58\n",
      "input [44, 53, 56, 1, 58, 46, 39, 58] gives target 1\n",
      "input [52] gives target 58\n",
      "input [52, 58] gives target 1\n",
      "input [52, 58, 1] gives target 58\n",
      "input [52, 58, 1, 58] gives target 46\n",
      "input [52, 58, 1, 58, 46] gives target 39\n",
      "input [52, 58, 1, 58, 46, 39] gives target 58\n",
      "input [52, 58, 1, 58, 46, 39, 58] gives target 1\n",
      "input [52, 58, 1, 58, 46, 39, 58, 1] gives target 46\n",
      "input [25] gives target 17\n",
      "input [25, 17] gives target 27\n",
      "input [25, 17, 27] gives target 10\n",
      "input [25, 17, 27, 10] gives target 0\n",
      "input [25, 17, 27, 10, 0] gives target 21\n",
      "input [25, 17, 27, 10, 0, 21] gives target 1\n",
      "input [25, 17, 27, 10, 0, 21, 1] gives target 54\n",
      "input [25, 17, 27, 10, 0, 21, 1, 54] gives target 39\n"
     ]
    }
   ],
   "source": [
    "# batch dimension\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'input {context.tolist()} gives target {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa2c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8235, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "yV!pOqR;tHZL,BBTsfez !mKq.FggmdzWAC3KR;.t?oxoHjr$BEaCIGV!mBzXefQioxoCXO.Ac;wrhc;comNYLPaMF\n",
      "p:cwn'O.S\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):        \n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None: # just get the logits\n",
    "            loss = None\n",
    "        else: # score the logits against targets\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # only focus on last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # convert to probabilities w/ softmax\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample next token from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sample to running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, \n",
    "                       max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a75666d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43],\n",
      "        [44, 53]])\n",
      "tensor([[43, 58],\n",
      "        [53, 56]])\n"
     ]
    }
   ],
   "source": [
    "ff = xb[:2, :2].contiguous()\n",
    "gg = yb[:2, :2].contiguous()\n",
    "print(ff)\n",
    "print(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6e58cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 65])\n",
      "2 2 65\n",
      "logits torch.Size([4, 65])\n",
      "torch.Size([2, 2])\n",
      "targets tensor([43, 58, 53, 56])\n",
      "tensor(4.7633, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = m.token_embedding_table(ff)\n",
    "print(logits.shape)\n",
    "B, T, C = logits.shape\n",
    "print(B,T,C)\n",
    "logits = logits.view(B*T, C)\n",
    "print(f\"logits {logits.shape}\")\n",
    "print(gg.shape)\n",
    "targets = gg.view(B*T)\n",
    "print(f\"targets {targets}\")\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8a55c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6294,  0.6927,  1.0668, -1.3627], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, 43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87c39ad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m r1, r2 \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/gpt_karpathy/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[17], line 13\u001B[0m, in \u001B[0;36mBigramLanguageModel.forward\u001B[0;34m(self, idx, targets)\u001B[0m\n\u001B[1;32m     11\u001B[0m     B, T, C \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m     12\u001B[0m     logits \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mview(B\u001B[38;5;241m*\u001B[39mT, C)\n\u001B[0;32m---> 13\u001B[0m     targets \u001B[38;5;241m=\u001B[39m \u001B[43mtargets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mB\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(logits, targets)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m logits, loss\n",
      "\u001B[0;31mRuntimeError\u001B[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "r1, r2 = m(ff, gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555edf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next up - Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e91c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
